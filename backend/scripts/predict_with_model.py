import pandas as pd
import joblib
from pathlib import Path
from collections import Counter
import json
import matplotlib.pyplot as plt

# í˜„ì¬ íŒŒì¼ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ backend ë””ë ‰í† ë¦¬ ê¸°ì¤€ ê²½ë¡œ í™•ë³´
BASE_DIR = Path(__file__).resolve().parent.parent  # backend/


def predict_churn(file_path: str, threshold: float = 0.5):
    # 1. ë°ì´í„° ë¡œë“œ
    df = pd.read_csv(file_path)
    df['last_login'] = pd.to_datetime(df['last_login'])
    df['days_since_login'] = (pd.Timestamp.today() - df['last_login']).dt.days

    # ì‹ ì› ì •ë³´ ë°±ì—…
    identity_df = df[['name', 'email', 'age', 'preferred_category']].copy()

    # 2. ë¨¸ì‹ ëŸ¬ë‹ ì…ë ¥ìš© ì»¬ëŸ¼ ì„ íƒ
    X = df[['age', 'watch_time', 'days_since_login']]  # í›ˆë ¨ì— ì‚¬ìš©í•œ featureë§Œ

    # 3. ì •ê·œí™” ë° ì˜ˆì¸¡
    scaler = joblib.load(BASE_DIR/"model/scaler.pkl")
    model = joblib.load(BASE_DIR/"model/model.pkl")
    X_scaled = scaler.transform(X)
    probs = model.predict_proba(X_scaled)[:, 1]


    print("ğŸ“Œ ì˜ˆì¸¡ í™•ë¥  ìƒìœ„ 10ê°œ:", probs[:10])
    print("ğŸ“Œ ì˜ˆì¸¡ í™•ë¥  ìµœì†Œ~ìµœëŒ€:", probs.min(), "~", probs.max())


    # 4. ê²°ê³¼ ê²°í•©
    result_df = identity_df.copy()
    result_df['churn_probability'] = probs
    print("ğŸ“Œ ë°›ì€ threshold:", threshold)
    result_df['is_high_risk'] = result_df['churn_probability'] > threshold
    # ğŸ”¥ ë°˜ë“œì‹œ í•„ìš”! ì´í›„ df.loc[...]ì—ì„œ ì˜¬ë°”ë¥´ê²Œ ë™ì‘í•˜ê²Œ í•˜ê¸° ìœ„í•´
    result_df.reset_index(drop=True, inplace=True)
    df.reset_index(drop=True, inplace=True)
    df["is_high_risk"] = result_df["is_high_risk"]

    # ğŸ”¥ ë””ë²„ê·¸ ì¶œë ¥
    print("ğŸ“Œ í™•ë¥  ìƒìœ„ 5ëª…:\n", result_df.sort_values(by="churn_probability", ascending=False).head())
    print("ğŸ“Œ is_high_risk True ê°œìˆ˜:", result_df['is_high_risk'].sum())

    # 5. ê·¸ë£¹ë³„ ë¶„ë¦¬
    churn_group = result_df[result_df["is_high_risk"] == True]
    non_churn_group = result_df[result_df["is_high_risk"] == False]

    # 6. ì—‘ì…€ë¡œ ì €ì¥ (ì§€í‘œ ìˆœì„œëŒ€ë¡œ ì •ë¦¬)
    # 6. ì—‘ì…€ë¡œ ì €ì¥ (ì§€í‘œ ìˆœì„œëŒ€ë¡œ ì •ë¦¬)
    high_risk_mask = result_df["is_high_risk"]
    excel_df = df[high_risk_mask].copy()
    excel_df["churn_probability"] = result_df[high_risk_mask]["churn_probability"].values
    excel_df = excel_df[["name", "age", "last_login", "watch_time", "preferred_category", "email", "churn_probability"]]



    # âœ… í¬ë§· ë³€ê²½
    excel_df["last_login"] = pd.to_datetime(excel_df["last_login"]).dt.strftime("%Y-%m-%d")
    excel_df["watch_time"] = pd.to_numeric(excel_df["watch_time"], errors="coerce").fillna(0).astype(int)
    excel_df["watch_time"] = excel_df["watch_time"].astype(str) + "ì‹œê°„"

    # âœ… ì €ì¥
    excel_path = BASE_DIR / "high_risk_customers.xlsx"
    excel_df.to_excel(excel_path, index=False)

    # 7. í†µê³„ ë°ì´í„° ìƒì„±
    stats = {
        "total_customers": len(result_df),
        "expected_churns": int(result_df["is_high_risk"].sum()),

        "average_age": {
            "churn": round(churn_group["age"].mean(), 2) if not churn_group.empty else 0,
            "non_churn": round(non_churn_group["age"].mean(), 2) if not non_churn_group.empty else 0,
        },
        "average_watch_time": {
            "churn": round(df.loc[result_df["is_high_risk"], "watch_time"].mean(), 2) if not churn_group.empty else 0,
            "non_churn": round(df.loc[~result_df["is_high_risk"], "watch_time"].mean(), 2) if not non_churn_group.empty else 0,
        },
        "average_days_since_login": {
            "churn": round(df.loc[result_df["is_high_risk"], "days_since_login"].mean(), 2) if not churn_group.empty else 0,
            "non_churn": round(df.loc[~result_df["is_high_risk"], "days_since_login"].mean(), 2) if not non_churn_group.empty else 0,
        },
        "genre_distribution": dict(Counter(result_df["preferred_category"]))
    }

    # 8. stats.json ì €ì¥ (ReactTest-main/public)
    stats_path = BASE_DIR.parent / "public/stats.json"
    stats_path.parent.mkdir(parents=True, exist_ok=True)
    with open(stats_path, "w", encoding="utf-8") as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)

    print("âœ… ì˜ˆì¸¡ ì™„ë£Œ: ê²°ê³¼ stats ìƒì„± ë° ì—‘ì…€ ì €ì¥ë¨")
    return result_df, churn_group, stats

